# 目标板定位模型
## 模型结构
### backbone
+ 输入需要满足的要求：  
    $$
        \frac{r}{3}=2^n 
    $$
    $$
        \frac{w}{4}=2^n    
    $$
    这样的设置是因为art的图像比例为4：3，然后一般进行下采样时是按步长为2进行。所以说可供选择的尺寸仅有（96，128），（48，64），更大或更小可能会出现模型运行速度较慢或精度较低等问题。
+ 考虑到兼容性问题，backbone使用了mobilenent v2的bottleneck结构。当然你也可以尝试一些比较新的tricks。有关bottleneck的介绍详见我的另一篇[文章](./docs/backbone.md)。
### 预测特征层
预测特征层只有一个：4x3     
在4x3的先验格子中，一个格子不会出现2个目标的情况    
正样本：4x3格子中有目标的格子   
负样本：4x3格子中无目标的格子   

### 分类头和回归头结构
+ 分类头：因为只有目标和背景两类，使用sigmoid激活所以分类头的输出为 (batch size,3,4,1)。
+ 回归头：因为只预测$c_x,c_y$两个值，所以回归头输出为 (batch size,3,4,2)。

## 目标编码与解码
### 目标编码
$$
    d_x = \frac{c_x-x_0}{w} 
$$
$$
    d_y = \frac{c_y-y_0}{h}
$$
$d_x,d_y为目标中心相对于先验格子中心偏移量的归一化值。c_x,c_y为目标的中心坐标。$
$x_0,y_0为先验格子的中心坐标。w，h为先验格子的宽和高。$

### 目标与先验格子的匹配策略
相邻的两个格子中心的距离为32，一个格子的大小为40。也就是说，相邻两个格子会有相交的区域。     
对于目标与先验格子的匹配，遵循以下两条原则：      
+ 第一原则：目标中心与某个格子的中心小于16，那么这个格子与目标匹配。
+ 第二原则：若格子尚为被匹配，则选取处于格子范围内且离格子中心最近的目标进行匹配。 

第一原则保证了每个目标都能与先验格子进行匹配，第二原则增加了正样本数，且避免了边界效应。    
注意：上述所有具体数值可以根据模型输入大小已经模型结构等因素进行调整。

## 损失函数  
将总体的目标损失函数定义为 定位损失（loc）和置信度损失（conf）的加权和：
$$
\begin{equation}
L(x,c,l,g) = \frac{1}{N}(L_{conf}(x,c)+\alpha L_{loc} (x,l,g))
\end{equation}
$$
$其中N为真实值中有目标的格子数，如果N=0，则将损失设为0；$
$而 α 参数用于调整置信度损失和定位损失之间的比例，默认 α=1。$
### 置信度损失  
因为为sigmoid激活后的二分类任务，使用交叉熵损失函数    
$$
\begin{equation}
    % L_{conf}(x,c) = -\sum_{i \in Pos}^N  log(\hat{c}_{i}) - \sum_{i \in Neg}^M log(\hat{c}_{i}) 
    L_{conf}(x,c) = -\sum (\ ylog(\hat{c_i}) +(1-y)log(\hat{c_i}) \ )
\end{equation}
$$
$$
    \hat{c_i} = Sigmoid(c_i)
$$
<!-- $Pos定义为格子上有目标的样本，Neg定义为格子上没有目标的样本。这里的有无目标指的是真实值，而非预测值。$ -->
$y=\left\{1，0\right\},当标签上有目标时为1，无目标时为零。其实就是Binary \ Crossentropy 损失。$

### 位置损失  
当且仅当预测与真实图片在某个格子内有目标时才进行计算（回归结果不在格子内也算，这就体现出Smooth L1 的价值了）。  
偏差为与格子中心进行归一化后的偏差（除以格子的边长）。      
使用Smooth L1 loss  
生成的标签为目标中心相对于格子中心的偏差。   
$$
\begin{equation}
    L_{loc}(x,l,g) = \sum_{i \in Pos }^N \sum_{m \in \left\{c_x,c_y\right\}} x_i smooth_{L1}(l_i^{m}- \hat{g}_i^{m})
\end{equation}
$$
$其中l为预测值的回归偏移量归一化值，\hat{g}为真实值的回归偏移量归一化值。$  
$x_i=\left\{1，0\right\}，当且仅当标签与预测都有目标时为1。$
### 正负样本比例
ssd中利用Hard negative mining方法得到1:3的正负样本比例。这里为了方便，直接利用数据生成器生产1:3正负样本比例的数据集，暂时不在损失函数部分实现Hard negative mining。

